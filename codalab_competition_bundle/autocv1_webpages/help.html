<h1>Help</h1>
<p><a name="help"></a></p>
<h3>Can organizers compete in the challenge?</h3>
<p>No, they can make entries that show on the leaderboard for test purposes and to stimulate participation, but they are excluded from winning prizes. Excluded entrants include:&nbsp;baseline0, baseline1, baseline2, baiyu, eric, hugo.jair, juliojj, Lukasz, madclam, Pavao, shangeth, thomas, tthomas, Zhen, Zhengying.</p>
<h3>Are there prerequisites to enter the challenge?</h3>
<p>No, except accepting the TERMS AND CONDITIONS.</p>
<h3>Can I enter any time?</h3>
<p>Yes, until the challenge deadline.</p>
<h3>Where can I download the data?</h3>
<p>You can download "public data" only from the Instructions page. The data on which your code is evaluated cannot be downloaded, it will be visible to your code only, on the Codalab platform.</p>
<h3>How do I make submissions?</h3>
<p>To make a valid challenge entry, make sure to click first the orange button "All datasets", then click the blue button on the upper right side "Upload a Submission". This will ensure that you submit on all 5 datasets of the challenge simultaneously. You may also make a submission on a single dataset for debug purposes, but it will not count towards the final ranking.</p>
<h3>Do you provide tips on how to get started?</h3>
<p>We provide a Starting Kit in Python with step-by-step instructions in a Jupyter notebook called "tutorial.ipynb", which can be found in the github repository&nbsp;<a href="https://github.com/zhengying-liu/autodl_starting_kit_stable">https://github.com/zhengying-liu/autodl_starting_kit_stable</a>. You can also have a well rendered preview <a href="https://nbviewer.jupyter.org/github/zhengying-liu/autodl_starting_kit_stable/blob/master/tutorial.ipynb">here</a>.</p>
<h3>Are there publication opportunities?</h3>
<p>Yes. Top ranking participants will be invited to submit papers to a&nbsp;<a href="https://drive.google.com/file/d/1_zYzXowLzLN7oJuQ-mdJ-YM-zBb60GE5/view?usp=sharing">special issue of the IEEE transaction journal PAMI on Automated Machine Learning</a>&nbsp;and will be entered in a contest for the best paper. Deadline November 30, 2019.</p>
<p>There will be 2 best paper awards of $1000 ("best paper" and "best student paper").</p>
<h3>Are there prizes?</h3>
<p>Yes, a 4000 USD prize pool.</p>
<table style="border-collapse: collapse;"><colgroup> <col style="width: 20.000000%;" /> <col style="width: 20.000000%;" /> <col style="width: 20.000000%;" /> <col style="width: 20.000000%;" /> <col style="width: 20.000000%;" /> </colgroup>
<tbody>
<tr>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">&nbsp;</td>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">
<div>
<div>
<p><span style="font-size: 10.000000pt; font-family: Arial; font-weight: bold;">1st place </span></p>
</div>
</div>
</td>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">
<div>
<div>
<p><span style="font-size: 10.000000pt; font-family: Arial; font-weight: bold;">2nd place </span></p>
</div>
</div>
</td>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">
<div>
<div>
<p><span style="font-size: 10.000000pt; font-family: Arial; font-weight: bold;">3rd place </span></p>
</div>
</div>
</td>
</tr>
<tr>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">
<div>
<div>
<p><span style="font-size: 10.000000pt; font-family: Arial; font-style: italic;">Prize </span></p>
</div>
</div>
</td>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">
<div>
<div>
<p><span style="font-size: 10.000000pt; font-family: ArialMT;">2000 USD </span></p>
</div>
</div>
</td>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">
<div>
<div>
<p><span style="font-size: 10.000000pt; font-family: ArialMT;">1500 USD </span></p>
</div>
</div>
</td>
<td style="border-style: solid; border-width: 0.750630pt; border-color: rgb(0.000000%,0.000000%,0.000000%);">
<div>
<div>
<p><span style="font-size: 10.000000pt; font-family: ArialMT;">500 USD </span></p>
</div>
</div>
</td>
</tr>
</tbody>
</table>
<h3>Do I need to submit code to participate?</h3>
<p>Yes, participation is by code submission.</p>
<h3>When I submit code, do I surrender all rights to that code to the SPONSORS or ORGANIZERS?</h3>
<p>No. You just grant to the ORGANIZERS a license to use your code for evaluation purposes during the challenge. You retain all other rights.</p>
<h3>If I win, I must submit a fact sheet, do you have a template?</h3>
<p>Yes, please download it <a href="https://forms.gle/WrpnZ1TKh9CY5AaRA">[HERE</a>].</p>
<h3>What is your CPU/GPU computational configuration?</h3>
<p>We are running your submissions on Google Cloud&nbsp;<span>NVIDIA Tesla P100 GPUs. In non peak times we are planning to use 10 workers, each of which will have one&nbsp;<span>NVIDIA Tesla P100 GPU (running&nbsp;CUDA 10 with drivers&nbsp;cuDNN 7.5) and 4</span><span>&nbsp;vCPUs, with 26 GB of memory</span></span>, 100 GB disk.</p>
<p>The PARTICIPANTS will be informed if the computational resources increase. They will NOT decrease.</p>
<h3>Can I pre-train a model on my local machine and submit it?</h3>
<p>This is not explicitly forbidden, but it is discouraged. We prefer if all calculations are performed on the server. If you submit a pre-trained model, you will have to disclose it in the fact sheets.&nbsp;</p>
<h3>Will there be a final test round on separate datasets?</h3>
<p>No. The ranking of participants will be made from the "All datasets" leaderboard, using the performances on all five datasets available on the platform. There will be no other testing on separate datasets.</p>
<h3>What is my time budget?</h3>
<p>Your execution must run in less than 20 minutes (1200 seconds) for each dataset. The cumulative time used for each dataset is limited to be less than 1 hour per day, which makes a total time of 5 hours on 5 datasets.</p>
<h3>Does the time budget correspond to wall time or CPU/GPU time?</h3>
<p>Wall time.</p>
<h3>My submission seems stuck, how long will it run?</h3>
<p>In principle no more than its time budget. We kill the process if the time budget is exceeded. Submissions are queued and run on a first time first serve basis. We are using several identical servers. Contact us if your submission is stuck more than 24 hours. Check on the leaderboard the execution time.</p>
<h3>How many submissions can I make?</h3>
<p>Five per day (and up to a total of 100), but up to a total computational time of 20 hours (submissions taking longer will be aborted). This may be subjet to change, according to the number of participants. Please respect other users. It is forbidden to register under multiple user IDs to gain an advantage and make more submissions. Violators will be DISQUALIFIED FROM THE CONTEST.</p>
<h3>Do my failed submissions count towards my number of submissions per day?</h3>
<p>No. Please contact us if you think the failure is due to the platform rather than to your code and we will try to resolve the problem promptly.</p>
<h3>What happens if I exceed my time budget?</h3>
<p>This should be avoided. In the case where a submission exceeds 2 hours of time budget for a particular task (dataset), the submission handling process (ingestion program in particular) will be killed when time budget is used up and predictions made so far (with their corresponding timestamps) will be used for evaluation. In the other case where a submission exceeds the total compute time per day, all running tasks will be killed by CodaLab and the status will be marked 'Failed' and a score of -1.0 will be produced.</p>
<h3>The time budget is too small, can you increase it?</h3>
<p>No sorry, not for this challenge.</p>
<h3>What metric are you using?</h3>
<p>All problems are multi-label problems and we treat them as multiple 2-class classification problems.&nbsp;For a given dataset, all binary classification problems are scored with the ROC AUC and results are averaged (over all classes/binary problems). For each time step at which you save results, this gives you one point on the learning curve. The final score for one dataset is the area under the learning curve. The overall score on all 5 datasets is the average rank on the 5 datasets. For more details, go to 'Get Started' -&gt; 'Instructions' -&gt; 'Metrics' section.</p>
<h3>Which version of Python are you using?</h3>
<p>The code was tested under Python 3.5. We are running Python 3.5 on the server and the same libraries are available.</p>
<h3>Can I use something else than Python code?</h3>
<p>Yes. Any Linux executable can run on the system, provided that it fulfills our Python interface and you bundle all necessary libraries with your submission.</p>
<h3>Do I have to use TensorFlow?</h3>
<p>No. We use TFRecords to format the datasets in a uniform manner, but you can use other software to process the data, including PyTorch (included in the Docker, see the following question).</p>
<h3>Which docker are you running on Codalab?</h3>
<p><strong>evariste/autodl:gpu</strong>, see the <a href="https://github.com/zhengying-liu/autodl/blob/master/docker/Dockerfile" target="_blank">Dockerfile</a> and some instructions on <a href="https://hub.docker.com/r/evariste/autodl">dockerhub</a>.</p>
<h3>How do I test my code in the same environment that you are using before submitting?</h3>
<p>When you submit code to Codalab, your code is executed inside a Docker container. This environment can be exactly reproduced on your local machine by downloading the corresponding docker image. The docker environment of the challenge contains Anaconda libraries, TensorFlow, and PyTorch (among other things).&nbsp;<br /> Non GPU users, if you are new to Docker, <a href="https://www.docker.com/get-started">follow these instructions to install docker.</a>&nbsp;You may then use the docker <strong>evariste/autodl:cpu</strong>.<strong> See details in the Starting Kit that can be downloaded from the Instructions page.&nbsp;</strong>GPU users, follow these <a href="https://github.com/NVIDIA/nvidia-docker/wiki">more detailed instructions</a>.</p>
<h3>What is meant by "Leaderboard modifying disallowed"?</h3>
<p>Your last submission is shown automatically on the leaderboard. You cannot choose which submission to select. If you want another submission than the last one you submitted to "count" and be displayed on the leaderboard, you need to re-submit it.</p>
<h3>Can I register multiple times?</h3>
<p>No. If you accidentally register multiple times or have multiple accounts from members of the same team, please notify the ORGANIZERS. Teams or solo PARTICIPANTS with multiple accounts will be disqualified.</p>
<h3>How can I create a team?</h3>
<p>We have disabled Codalab team registration. To join as a team, just share one account with your team. The team leader is responsible for making submissions and observing the rules.</p>
<h3>How can I destroy a team?</h3>
<p>You cannot. If you need to destroy your team, contact us.</p>
<h3>Can I join or leave a team?</h3>
<p>It is up to you and the team leader to make arrangements. However, you cannot participate in multiple teams.</p>
<h3>Can cheat by trying to get a hold of the evaluation data and/or future frames while my code is running?</h3>
<p>No. If we discover that you are trying to cheat in this way you will be disqualified. All your actions are logged and your code will be examined if you win.</p>
<h3>Can I give an arbitrary hard time to the ORGANIZERS?</h3>
<p>ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED "AS-IS". UPSUD, CHALEARN, IDF, AND/OR OTHER ORGANIZERS AND SPONSORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL ISABELLE GUYON AND/OR OTHER ORGANIZERS BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. In case of dispute or possible exclusion/disqualification from the competition, the PARTICIPANTS agree not to take immediate legal action against the ORGANIZERS or SPONSORS. Decisions can be appealed by submitting a letter to the CHALEARN president, and disputes will be resolved by the CHALEARN board of directors. See <a href="http://www.chalearn.org/contact-us.html">contact information.</a></p>
<h3>Where can I get additional help?</h3>
<p>For questions of general interest, THE PARTICIPANTS should post their questions to the forum.</p>
<p>Other questions should be directed to <a href="mailto:autodl@chalearn.org">the organizers</a>.</p>